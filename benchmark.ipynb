{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43738d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Imports necessaris\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, List, TypedDict\n",
    "from duckduckgo_search import DDGS\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ce24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dades de referència amb el model gpt-4.5\n",
    "with open(\"resultats/resultats_4_5.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_4_5 = json.load(f)\n",
    "\n",
    "# Carreguem el dataset de notícies\n",
    "file_path = '../final_dataset_v2.csv'  \n",
    "# Step 3: Read the CSV file\n",
    "df = pd.read_csv(file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a1feba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creem una funció per trobar tots els articles que tenen almenys un \"No\" en compliment\n",
    "def find_articles_with_no_compliment(data_json):\n",
    "    # Dictionary to store article_id → full JSON for those with at least one \"No\" in compliment\n",
    "    articles_with_no_dict = {}\n",
    "\n",
    "    # Iterate through each article's analysis\n",
    "    for article_id, criteria in data_json.items():\n",
    "        for key, value in criteria.items():\n",
    "            if isinstance(value, dict):\n",
    "                if value.get(\"compliment\", \"\").strip().lower() == \"no\":\n",
    "                    articles_with_no_dict[article_id] = criteria\n",
    "                    break  # Skip remaining keys for this article\n",
    "\n",
    "    return articles_with_no_dict\n",
    "\n",
    "# Ara una funció per comptar el nombre de criteris per cada tema\n",
    "def count_criteria_by_topic(data_json):\n",
    "\n",
    "    # Count compliments for each category across all articles\n",
    "    category_counts = {}\n",
    "\n",
    "    for article in data_json.values():\n",
    "        for category, values in article.items():\n",
    "            compliment = values.get(\"compliment\", \"\").strip()\n",
    "            if category not in category_counts:\n",
    "                category_counts[category] = {\"Sí\": 0, \"No\": 0, \"No aplica\": 0}\n",
    "            if compliment in category_counts[category]:\n",
    "                category_counts[category][compliment] += 1\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    df_category_counts = pd.DataFrame.from_dict(category_counts, orient='index')\n",
    "    df_category_counts.index.name = \"Category\"\n",
    "    return df_category_counts\n",
    "\n",
    "def clean_json_output(raw_output):\n",
    "    # Remove triple backticks and optional \"json\" marker\n",
    "    cleaned = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", raw_output.strip(), flags=re.IGNORECASE | re.MULTILINE)\n",
    "    return cleaned\n",
    "\n",
    "class Criterion(TypedDict):\n",
    "    compliment: Literal[\"Sí\", \"No\", \"No aplica\"]\n",
    "    comentari: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded2e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99295e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-0613\n",
      "gpt-4\n",
      "gpt-3.5-turbo\n",
      "gpt-audio\n",
      "gpt-5-nano\n",
      "gpt-audio-2025-08-28\n",
      "gpt-realtime\n",
      "gpt-realtime-2025-08-28\n",
      "davinci-002\n",
      "babbage-002\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "dall-e-3\n",
      "dall-e-2\n",
      "gpt-4-1106-preview\n",
      "gpt-3.5-turbo-1106\n",
      "tts-1-hd\n",
      "tts-1-1106\n",
      "tts-1-hd-1106\n",
      "text-embedding-3-small\n",
      "text-embedding-3-large\n",
      "gpt-4-0125-preview\n",
      "gpt-4-turbo-preview\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini\n",
      "gpt-4o-2024-08-06\n",
      "chatgpt-4o-latest\n",
      "o1-mini-2024-09-12\n",
      "o1-mini\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-realtime-preview\n",
      "omni-moderation-latest\n",
      "omni-moderation-2024-09-26\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "o1-2024-12-17\n",
      "o1\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-audio-preview\n",
      "computer-use-preview\n",
      "o3-mini\n",
      "o3-mini-2025-01-31\n",
      "gpt-4o-2024-11-20\n",
      "computer-use-preview-2025-03-11\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "gpt-4o-search-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4o-transcribe\n",
      "gpt-4o-mini-transcribe\n",
      "o1-pro-2025-03-19\n",
      "o1-pro\n",
      "gpt-4o-mini-tts\n",
      "o3-2025-04-16\n",
      "o4-mini-2025-04-16\n",
      "o3\n",
      "o4-mini\n",
      "gpt-4.1-2025-04-14\n",
      "gpt-4.1\n",
      "gpt-4.1-mini-2025-04-14\n",
      "gpt-4.1-mini\n",
      "gpt-4.1-nano-2025-04-14\n",
      "gpt-4.1-nano\n",
      "gpt-image-1\n",
      "codex-mini-latest\n",
      "o3-pro\n",
      "gpt-4o-realtime-preview-2025-06-03\n",
      "gpt-4o-audio-preview-2025-06-03\n",
      "o3-pro-2025-06-10\n",
      "o4-mini-deep-research\n",
      "o3-deep-research\n",
      "o3-deep-research-2025-06-26\n",
      "o4-mini-deep-research-2025-06-26\n",
      "gpt-5-chat-latest\n",
      "gpt-5-2025-08-07\n",
      "gpt-5\n",
      "gpt-5-mini-2025-08-07\n",
      "gpt-5-mini\n",
      "gpt-5-nano-2025-08-07\n",
      "gpt-3.5-turbo-16k\n",
      "tts-1\n",
      "whisper-1\n",
      "text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# Ara cal triar el model a avaluar i afegir la key\n",
    "\n",
    "# TRIAR EL MODEL\n",
    "# llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)   # gpt-5 no suporta temperatura 0\n",
    "llm = ChatOpenAI(model=\"gpt-5\", temperature=1)  # gpt-4 i 4.1 suporten temperatura 0\n",
    "\n",
    "# CARREGAR KEY\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Models disponiblees de openai \n",
    "models = openai.models.list()\n",
    "for model in models:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361dbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad1d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuació es recuperen els templates que s'utilitzaran per a la prova-benchmarking\n",
    "# Els templates es troben a la carpeta \"prompts\"\n",
    "# Hi ha un total de 7 templates, un per cada tema a avaluar\n",
    "# Els temes a avaluar són:\n",
    "# Plurallisme, diversitat, minories, paritat i equilibri de gènere, compromís, veracitat i rigor, independència i imparcialitat i neutralitat, denominacions, model de llenguatge i adequació\n",
    "# Aquests templates es poden modificar i són els que seran utilizats per fer la prova-benchmarking\n",
    "\n",
    "# Si es volen modificar els templates, cal fer-ho a la carpeta \"prompts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45da8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anem a recuperar els templates de la carpeta \"prompts\"\n",
    "\n",
    "with open(\"prompts/1_pluralisme.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    prompt_pluralisme = file.read()\n",
    "\n",
    "with open(\"prompts/2_diversitat.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    prompt_diversitat = file.read()\n",
    "\n",
    "with open(\"prompts/3_minories.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    prompt_minories = file.read()\n",
    "\n",
    "with open(\"prompts/4_paritat.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    prompt_paritat = file.read()\n",
    "\n",
    "with open(\"prompts/5_compromis.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    prompt_compromis = file.read()\n",
    "\n",
    "with open(\"prompts/6_veracitat.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    prompt_veracitat = file.read()\n",
    "\n",
    "with open(\"prompts/7_imparcialitat.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    prompt_imparcialitat = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c26a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "pluralisme_promt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_pluralisme\n",
    ")\n",
    "\n",
    "diversitat_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_diversitat\n",
    ")\n",
    "\n",
    "minories_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_minories\n",
    ")\n",
    "\n",
    "paritat_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_paritat\n",
    ")\n",
    "\n",
    "compromis_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_compromis\n",
    ")\n",
    "\n",
    "veracitat_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_veracitat\n",
    ")\n",
    "\n",
    "imparcialitat_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_imparcialitat\n",
    ")\n",
    "\n",
    "# Pipelines\n",
    "pluralisme_pipeline = pluralisme_promt | llm.with_structured_output(Criterion)\n",
    "diversitat_pipeline = diversitat_prompt | llm.with_structured_output(Criterion)\n",
    "minories_pipeline = minories_prompt | llm.with_structured_output(Criterion)\n",
    "paritat_pipeline = paritat_prompt | llm.with_structured_output(Criterion)\n",
    "compromis_pipeline = compromis_prompt | llm.with_structured_output(Criterion)\n",
    "veracitat_pipeline = veracitat_prompt | llm.with_structured_output(Criterion)\n",
    "imparcialitat_pipeline = imparcialitat_prompt | llm.with_structured_output(Criterion)\n",
    "\n",
    "\n",
    "def pluralisme_analysis(article_text: str):\n",
    "    \"\"\"\n",
    "    Analyzes the pluralisme aspect of a short article.\n",
    "    \"\"\"\n",
    "    result = pluralisme_pipeline.invoke({\"text\": article_text})\n",
    "    return result\n",
    "\n",
    "def diversitat_analysis(article_text: str):\n",
    "    \"\"\"\n",
    "    Analyzes the diversitat aspect of a short article.\n",
    "    \"\"\"\n",
    "    result = diversitat_pipeline.invoke({\"text\": article_text})\n",
    "    return result\n",
    "\n",
    "def minories_analysis(article_text: str):\n",
    "    \"\"\"\n",
    "    Analyzes the minories aspect of a short article.\n",
    "    \"\"\"\n",
    "    result = minories_pipeline.invoke({\"text\": article_text})\n",
    "    return result\n",
    "\n",
    "def paritat_analysis(article_text: str):\n",
    "    \"\"\"\n",
    "    Analyzes the paritat and equilibri de gènere aspect of a short article.\n",
    "    \"\"\"\n",
    "    result = paritat_pipeline.invoke({\"text\": article_text})\n",
    "    return result\n",
    "\n",
    "def compromis_analysis(article_text: str):\n",
    "    \"\"\"\n",
    "    Analyzes the compromis aspect of a short article.\n",
    "    \"\"\"\n",
    "    result = compromis_pipeline.invoke({\"text\": article_text})\n",
    "    return result\n",
    "\n",
    "def veracitat_analysis(article_text: str):\n",
    "    \"\"\"\n",
    "    Analyzes the veracitat and rigor aspect of a short article.\n",
    "    \"\"\"\n",
    "    result = veracitat_pipeline.invoke({\"text\": article_text})\n",
    "    return result\n",
    "\n",
    "def imparcialitat_analysis(article_text: str):\n",
    "    \"\"\"\n",
    "    Analyzes the independence, impartiality, and neutrality aspect of a short article.\n",
    "    \"\"\"\n",
    "    result = imparcialitat_pipeline.invoke({\"text\": article_text})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceefb313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article 1 of 134...\n",
      "Processing article 10 of 134...\n",
      "Processing article 20 of 134...\n",
      "Processing article 30 of 134...\n",
      "Processing article 40 of 134...\n",
      "Processing article 50 of 134...\n",
      "Processing article 60 of 134...\n",
      "Processing article 70 of 134...\n",
      "Processing article 80 of 134...\n",
      "Processing article 90 of 134...\n",
      "Processing article 100 of 134...\n",
      "Processing article 110 of 134...\n",
      "Processing article 120 of 134...\n",
      "Processing article 130 of 134...\n"
     ]
    }
   ],
   "source": [
    "# BENCHMARK AMB EL MODEL SELECCIONAT\n",
    "\n",
    "# Analitzem amb el nou model les notícies\n",
    "analysis_functions = [\n",
    "    pluralisme_analysis,\n",
    "    diversitat_analysis,\n",
    "    minories_analysis,\n",
    "    paritat_analysis,\n",
    "    compromis_analysis,\n",
    "    veracitat_analysis,\n",
    "    imparcialitat_analysis\n",
    "]\n",
    "\n",
    "# Utilitzem els ids que teníem al dataset\n",
    "ids = data_4_5.keys()\n",
    "ids = [int(id) for id in ids]\n",
    "\n",
    "df_benchmark = df[df['id'].isin(ids)].reset_index(drop=True).copy()\n",
    "\n",
    "# Diccionari per guardar tots els resultats del nou model\n",
    "all_results = {}\n",
    "j = 0\n",
    "\n",
    "# --- Loop over each sampled row ---\n",
    "for i, row in df_benchmark.iterrows():\n",
    "    j += 1\n",
    "    if j % 10 == 0 or j == 1:\n",
    "        print(f\"Processing article {j} of {len(df_benchmark)}...\")\n",
    "\n",
    "    article_id = str(row[\"id\"])\n",
    "    text = row[\"cos\"]\n",
    "    merged_result = {}\n",
    "\n",
    "    for func in analysis_functions:\n",
    "        try:\n",
    "            result = func(text)\n",
    "\n",
    "            # Si és una instància Pydantic, convertim a dict\n",
    "            if hasattr(result, 'dict'):\n",
    "                result = result.dict()\n",
    "\n",
    "            merged_result.update(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in {func.__name__} for article {article_id}: {e}\")\n",
    "            merged_result[func.__name__] = {\"error\": str(e)}\n",
    "\n",
    "    # Guardem al diccionari global\n",
    "    all_results[article_id] = merged_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da3059bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIAR EL NOM DEL FITXER ON ES GUARDEN ELS RESULTATS\n",
    "nom = \"resultats_gpt5_2\"\n",
    "with open(f\"resultats/{nom}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ed2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground_3cat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
